{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Farmer Technology Adoption Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import lightgbm as lgb\n",
    "import ast\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('Train.csv')\n",
    "test_df = pd.read_csv('Test.csv')\n",
    "sample_submission_df = pd.read_csv('SampleSubmission.csv')\n",
    "\n",
    "# Requirement 1: Index Generalization\n",
    "train_df.set_index('ID', inplace=True)\n",
    "test_df.set_index('ID', inplace=True)\n",
    "\n",
    "print('Training data shape:', train_df.shape)\n",
    "print('Test data shape:', test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(df):\n",
    "    # Requirement 2: Temporal Engineering\n",
    "    df['first_training_date'] = pd.to_datetime(df['first_training_date'])\n",
    "    df['month'] = df['first_training_date'].dt.month\n",
    "    df['week'] = df['first_training_date'].dt.isocalendar().week.astype(int)\n",
    "    df['day'] = df['first_training_date'].dt.day\n",
    "    \n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
    "    df['week_sin'] = np.sin(2 * np.pi * df['week']/52)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day']/31)\n",
    "    \n",
    "    # Requirement 3: Behavioral Engineering\n",
    "    df['topics_list'] = df['topics_list'].apply(ast.literal_eval)\n",
    "    df['topic_count'] = df['topics_list'].apply(len)\n",
    "    \n",
    "    df['Biogas_Interest'] = df['topics_list'].apply(lambda x: 1 if 'biogas' in [topic.lower() for topic in x] else 0)\n",
    "    df['Poultry_Focus'] = df['topics_list'].apply(lambda x: 1 if 'poultry' in [topic.lower() for topic in x] else 0)\n",
    "    df['Dairy_Focus'] = df['topics_list'].apply(lambda x: 1 if 'dairy' in [topic.lower() for topic in x] else 0)\n",
    "\n",
    "    # Requirement 4: Feature Engineering\n",
    "    df['training_intensity'] = df['num_repeat_trainings'] / (df['num_total_trainings'] + 1e-6)\n",
    "    \n",
    "    # Requirement 4: Handle missing values\n",
    "    df['days_to_second_training_missing'] = df['days_to_second_training'].isnull().astype(int)\n",
    "    df['days_to_second_training'].fillna(-999, inplace=True) # Sentinel value\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = feature_engineer(train_df)\n",
    "test_df = feature_engineer(test_df)\n",
    "\n",
    "print('Feature engineering complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 4: Label Encoding for geographic and trainer fields\n",
    "categorical_features = ['county', 'subcounty', 'ward', 'trainer']\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "    test_df[col] = le.transform(test_df[col].astype(str))\n",
    "    \n",
    "print('Categorical encoding complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'age', 'gender', 'access_to_credit', 'education_level',\n",
    "    'farming_experience', 'farm_size', 'income_source', 'district',\n",
    "    'num_total_trainings', 'num_repeat_trainings', 'training_topic_most_frequent',\n",
    "    'group_size', 'contact_preference', 'preferred_training_method', 'county', 'subcounty', 'ward', 'trainer',\n",
    "    'days_to_second_training', 'month_sin', 'week_sin', 'day_sin', 'topic_count',\n",
    "    'Biogas_Interest', 'Poultry_Focus', 'Dairy_Focus', 'training_intensity',\n",
    "    'days_to_second_training_missing'\n",
    "]\n",
    "targets = ['adopted_within_07_days', 'adopted_within_90_days', 'adopted_within_120_days']\n",
    "\n",
    "# Align columns - crucial for consistent feature sets\n",
    "train_cols = train_df.columns\n",
    "test_cols = test_df.columns\n",
    "shared_cols = list(set(train_cols) & set(test_cols))\n",
    "features = [col for col in features if col in shared_cols]\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[targets]\n",
    "X_test = test_df[features]\n",
    "\n",
    "# Requirement 5: Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Data shapes:')\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_val:', X_val.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_val:', y_val.shape)\n",
    "print('X_test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 6: Train a multi-output probabilistic model\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'logloss',\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "base_estimator = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "model = MultiOutputClassifier(estimator=base_estimator)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('Model training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submission Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 7: Generate predictions for the Test.csv data\n",
    "test_probabilities = model.predict_proba(X_test)\n",
    "\n",
    "# The output of predict_proba for MultiOutputClassifier is a list of arrays\n",
    "prob_07 = test_probabilities[0][:, 1]\n",
    "prob_90 = test_probabilities[1][:, 1]\n",
    "prob_120 = test_probabilities[2][:, 1]\n",
    "\n",
    "# Requirement 7: Format the final CSV\n",
    "submission_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "submission_df['Target_07_AUC'] = prob_07\n",
    "submission_df['Target_90_AUC'] = prob_90\n",
    "submission_df['Target_120_AUC'] = prob_120\n",
    "\n",
    "# Assign the same probability scores to LogLoss columns\n",
    "submission_df['Target_07_LogLoss'] = prob_07\n",
    "submission_df['Target_90_LogLoss'] = prob_90\n",
    "submission_df['Target_120_LogLoss'] = prob_120\n",
    "\n",
    "# Ensure the columns are in the correct order\n",
    "submission_df = submission_df[sample_submission_df.columns[1:]]\n",
    "\n",
    "submission_df.to_csv('submission.csv')\n",
    "\n",
    "print('Submission file created successfully!')\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
